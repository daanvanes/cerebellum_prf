{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Regress out nuissance variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from nistats.regression import OLSModel\n",
    "from joblib import Parallel, delayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup dirs\n",
    "home_dir = '/home/shared/2018/visual/cerebellum_prf/'\n",
    "der_dir = os.path.join(home_dir,'derivatives')\n",
    "out_dir = os.path.join(home_dir,'derivatives','pp')\n",
    "in_dir = os.path.join(out_dir,'sgtf')\n",
    "ng_out_dir = os.path.join(out_dir,'ng')\n",
    "if not os.path.isdir(ng_out_dir): os.mkdir(ng_out_dir)\n",
    "\n",
    "\n",
    "subs = ['02']#,'02','03']\n",
    "sess = {\n",
    "    '01':['01','03','02'],\n",
    "    '02':['01','02','03','04'],\n",
    "    '03':['01','02','03']\n",
    "}\n",
    "\n",
    "TR = 1.5\n",
    "space = 'MNI152NLin2009cAsym' # 'T1w'\n",
    "\n",
    "n_components =5 # number of pca components to regress out\n",
    "\n",
    "# grab these variables from nuissance file:\n",
    "varr = [\n",
    "    'stdDVARS',\n",
    "    'non-stdDVARS',\n",
    "    'vx-wisestdDVARS',\n",
    "    'FramewiseDisplacement',\n",
    "    'aCompCor00',\n",
    "    'aCompCor01',\n",
    "    'aCompCor02',\n",
    "    'aCompCor03',\n",
    "    'aCompCor04',\n",
    "    'aCompCor05',\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'RotX',\n",
    "    'RotY',\n",
    "    'RotZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savgol_filter(data, polyorder=3, deriv=0, window_length = 120,TR=1.5):\n",
    "    \"\"\" Applies a savitsky-golay filter to a nifti-file.\n",
    "\n",
    "    Fits a savitsky-golay filter to a 4D fMRI nifti-file and subtracts the\n",
    "    fitted data from the original data to effectively remove low-frequency\n",
    "    signals.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.signal import savgol_filter\n",
    "\n",
    "    window = np.int(window_length / TR)\n",
    "\n",
    "    # Window must be odd\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "\n",
    "    data_filt = savgol_filter(data, window_length=window, polyorder=polyorder,\n",
    "                              deriv=deriv, mode='nearest')\n",
    "\n",
    "    data_filtered = data - data_filt + data_filt.mean()\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_ng(in_dir,out_dir,fn,ses):\n",
    "    # determine out fn\n",
    "    out_fn = fn.replace(in_dir,out_dir).replace('.nii.gz','_ng.nii.gz')\n",
    "\n",
    "    if not os.path.isfile(out_fn):\n",
    "\n",
    "        run = fn.split('/')[-1].split('_')[3].split('-')[-1]\n",
    "\n",
    "        # load nuissance file\n",
    "        fmriprepdir = 'fmriprep_ses%s'%ses\n",
    "        df_fn = os.path.join(der_dir,fmriprepdir,'fmriprep','sub-%s'%sub,'ses-%s'%ses,'func','sub-%s_ses-%s_task-prf_run-%s_bold_confounds.tsv'%(sub,ses,run))\n",
    "        df = pd.DataFrame.from_csv(df_fn, sep='\\t', header=0,index_col=None)\n",
    "\n",
    "        # get the wanted variables and do stuff with it\n",
    "        nuissances = []\n",
    "        for var in varr:\n",
    "\n",
    "            # get wanted nuissance variables\n",
    "            data = np.array(df[var])\n",
    "            # fill in nans\n",
    "            data[data=='n/a'] = np.nan\n",
    "            # cast to float\n",
    "            data = data.astype('float32')\n",
    "            # median fill nan values (i.e. first value )\n",
    "            data[np.isnan(data)] = np.nanmedian(data)\n",
    "            # temporally filter \n",
    "            filtered_data = savgol_filter(data)\n",
    "            # z-score (so that explained variance ratios is interpretable)\n",
    "            filtered_data_z = (filtered_data - np.mean(filtered_data)) / np.std(filtered_data)\n",
    "            # and append\n",
    "            nuissances.append(filtered_data_z)\n",
    "\n",
    "        nuissances = np.array(nuissances)    \n",
    "\n",
    "        # now do pca and grab first 5:\n",
    "        pca = PCA(n_components=n_components)  \n",
    "        pcas = pca.fit_transform(nuissances.T)\n",
    "\n",
    "        # now load data\n",
    "        img = nb.load(fn)\n",
    "        data = np.nan_to_num(img.get_data())\n",
    "        datashape = data.shape\n",
    "\n",
    "        # do nuissance regression\n",
    "        dm = np.hstack([np.ones((pcas.shape[0],1)),pcas]) # add intercept\n",
    "        model = OLSModel(dm)\n",
    "        fit = model.fit(data.reshape(-1,datashape[-1]).T)\n",
    "        resid = fit.resid.T.reshape(datashape)\n",
    "        resid += np.mean(data,axis=-1)[:,:,:,np.newaxis] # re-add the signal offset which was regressed out by the intercept\n",
    "        \n",
    "        # save\n",
    "        new_img = nb.Nifti1Image(resid,affine=img.affine,header=img.header)\n",
    "        nb.save(new_img,out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now removing nuisances from sub 02, ses 01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   4 out of  13 | elapsed:  1.5min remaining:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done   6 out of  13 | elapsed:  1.5min remaining:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done   8 out of  13 | elapsed:  2.7min remaining:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  13 | elapsed:  2.7min remaining:   49.4s\n",
      "[Parallel(n_jobs=6)]: Done  13 out of  13 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now removing nuisances from sub 02, ses 02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   8 | elapsed:  1.4min remaining:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   8 | elapsed:  1.4min remaining:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   8 | elapsed:  1.4min remaining:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   8 | elapsed:  1.4min remaining:   51.9s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   8 | elapsed:  1.5min remaining:   29.0s\n",
      "[Parallel(n_jobs=6)]: Done   8 out of   8 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   8 out of   8 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now removing nuisances from sub 02, ses 03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   3 out of  10 | elapsed:  1.4min remaining:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done   5 out of  10 | elapsed:  1.4min remaining:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done   7 out of  10 | elapsed:  2.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now removing nuisances from sub 02, ses 04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   6 out of  15 | elapsed:  1.4min remaining:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done   8 out of  15 | elapsed:  2.7min remaining:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  15 | elapsed:  2.7min remaining:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done  12 out of  15 | elapsed:  2.8min remaining:   41.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  15 out of  15 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "for sub in subs:\n",
    "    for ses in sess[sub]:\n",
    "        \n",
    "        print('now removing nuisances from sub %s, ses %s'%(sub,ses))\n",
    "\n",
    "        # setup output\n",
    "        sj_ng_out_dir = os.path.join(ng_out_dir,'sub-%s'%sub)\n",
    "        if not os.path.isdir(sj_ng_out_dir): os.mkdir(sj_ng_out_dir)\n",
    "\n",
    "        # get input fns\n",
    "        sj_in_dir = os.path.join(in_dir,'sub-%s'%sub)\n",
    "        fns = sorted(glob.glob(os.path.join(sj_in_dir,'sub-%s_ses-%s*bold_space-%s_preproc_resampled_fnirted_smoothed_sgtf.nii.gz'%(sub,ses,space))))\n",
    "\n",
    "        # loop over runs and perform nuissance regresison per run\n",
    "        Parallel(n_jobs=6,verbose=9)(delayed(perform_ng)(sj_in_dir,sj_ng_out_dir,fn,ses) for fn in fns)\n",
    "\n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [analysis]",
   "language": "python",
   "name": "Python [analysis]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
